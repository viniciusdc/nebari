render-qhub:
  image: "python:3.9"
  variables:
    COMMIT_MSG: |
      qhub-config.yaml automated commit: {{ '$CI_COMMIT_SHA' }}
  script:
    - pip install qhub==0.2.3
    - qhub render -c qhub-config.yaml
    - git config user.email "qhub@quansight.com"
    - git config user.name "gitlab ci"
    - git add .
    - git diff --quiet && git diff --staged --quiet || (git commit -m "${COMMIT_MSG}"; git push origin master)
  only:
    refs:
      - master
    changes:
      - "qhub-config.yaml"

build-docker-images:
  services:
    - docker:dind
  image: "docker:19.03.12"
  timeout: 2h
  parallel:
    matrix:
      - DOCKERFILE:
          - jupyterlab
          - jupyterhub
          - dask-worker
  variables:
    IMAGE_TAG: {{ '$CI_COMMIT_SHA' }}
    IMAGE_NAME: {{ cookiecutter.project_name }}-{{ '$DOCKERFILE' }}
  script:
    - docker build -f "image/Dockerfile.{{ '$DOCKERFILE' }}" -t "$IMAGE_NAME:$IMAGE_TAG" image
  only:
    refs:
      - merge_requests
    variables:
      - $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "master"
    changes:
      - "image/**"

terraform-jupyterhub:
  image:
    name: "hashicorp/terraform"
    entrypoint: [""]
  variables: 
    PROVIDER: {{ cookiecutter.provider }}
    PREFECT: {{ cookiecutter.prefect }}   
    WORKSPACE: infrastructure/
    VARS: ""
  rules:
    - if: $CI_COMMIT_REF_NAME == /master/
      changes:
        - "infrastructure/**" 
        - "environments/**"
    
    - if: $PREFECT
      variables:
        VARS: '-var="prefect_token=${{ secrets.PREFECT_TOKEN }}"'

    - if: $PROVIDER == 'aws'
      variables:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}

    - if: $PROVIDER == 'do'
      variables:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        AWS_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
        SPACES_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY_ID }}
        SPACES_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
        DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}

    - if: $PROVIDER == 'gcp'
      variables:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

    - if: $PROVIDER == 'azure'
      variables:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
        ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
        ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}

  before_script:
    - terraform version

  script: |
    terraform fmt ${WORKSPACE}
    terraform init ${WORKSPACE}
    terraform validate ${WORKSPACE}
    terraform plan ${VARS} ${WORKSPACE}
    terraform apply ${VARS} ${WORKSPACE}

qhub-build-dockerfiles:
  services:
    - docker:dind
  parallel:
    matrix:
      - DOCKERFILE:
          - jupyterlab
          - jupyterhub
          - dask-worker
{% if cookiecutter.provider == "aws" %}
  image:
    name: amazon/aws-cli
    entrypoint: [""]

  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_IMAGE_NAME: {{ cookiecutter.project_name }}-{{ '$DOCKERFILE' }}
    IMAGE_TAG: {{ '$CI_COMMIT_SHA' }}
    AWS_ACCESS_KEY_ID: '${{ secrets.AWS_ACCESS_KEY_ID }}'
    AWS_SECRET_ACCESS_KEY: '${{ secrets.AWS_SECRET_ACCESS_KEY }}'
    AWS_DEFAULT_REGION: '${{ secrets.AWS_DEFAULT_REGION }}'
  
  before_script:
    - amazon-linux-extras install docker
    - aws --version
    - docker --version

  script:
    - yum -y install jq
    - export ACCOUNT_ID=$( aws sts get-caller-identity | jq -r '.Account' ) 
    - export ECR_REGISTRY=$ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
    - export IMAGE_NAME=$ECR_REGISTRY/$DOCKER_IMAGE_NAME
    - docker build -f "image/Dockerfile.$DOCKERFILE" -t $IMAGE_NAME:$IMAGE_TAG image
    - aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_REGISTRY
    - docker push $IMAGE_NAME:$IMAGE_TAG
    - docker logout "$ECR_REGISTRY"
{% elif cookiecutter.provider == "gcp" %}
  image:
    name: google/cloud-sdk

  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_IMAGE_NAME: {{ cookiecutter.project_name }}/qhub-{{ '$DOCKERFILE' }}
    IMAGE_TAG: {{ '$CI_COMMIT_SHA' }}
    PROJECT_ID: {{ '${{ secrets.PROJECT_ID }}' }}
    GCP_CREDENTIALS: {{ '${{ secrets.GCP_CREDENTIALS }}' }}


  before_script:
    - docker --version
    - export GOOGLE_CREDENTIALS=$(echo $GCP_CREDENTIALS | base64 -d)
    - echo "$GOOGLE_CREDENTIALS" > /tmp/service-account.json
    - gcloud auth activate-service-account --key-file=/tmp/service-account.json

  script:
    - gcloud auth configure-docker
    - export IMAGE_NAME="gcr.io/$PROJECT_ID/$DOCKER_IMAGE_NAME"
    - docker build -f "image/Dockerfile.$DOCKERFILE" -t $IMAGE_NAME:$IMAGE_TAG image
    - docker push $IMAGE_NAME:$IMAGE_TAG
    - docker logout
{% endif %}
  only:
    refs:
      - master
    changes:
      - "image/**"





